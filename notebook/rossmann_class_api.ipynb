{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a5f3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b902de8",
   "metadata": {},
   "source": [
    "## <font Color=\"Blue\">10.1 Rossmann Class</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Import Libraries ------------------\n",
    "import pickle\n",
    "import inflection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "class Rossmann( object ):\n",
    "    \n",
    "    # ----- Load Trained Model ------------------------------------------------\n",
    "    def __init__( self ):\n",
    "        self.home_path ='C:/Users/frmoriya/Documents/repos/ds_producao_hosmann/'\n",
    "        self.competition_distance_scaler   = pickle.load( open( self.home_path + 'parameters/competition_distance_scaler.pkl', 'rb'))\n",
    "        self.competition_time_month_scaler = pickle.load( open( self.home_path + 'parameters/competition_time_month_scaler.pkl', 'rb'))\n",
    "        self.promo_time_week_scaler        = pickle.load( open( self.home_path + 'parameters/promo_time_week_scaler.pkl', 'rb'))\n",
    "        self.year_scaler                   = pickle.load( open( self.home_path + 'parameters/year_scaler.pkl', 'rb'))\n",
    "        self.store_type_scaler             = pickle.load( open( self.home_path + 'parameters/store_type_scaler.pkl', 'rb'))\n",
    "        \n",
    "        \n",
    "    def data_cleaning( self, df1):\n",
    "        \n",
    "        # ---- 1.1 Rename Columns ----------------------------------------------\n",
    "        cols_old =['Store', 'DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday', \n",
    "                   'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "                    'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "        snakecase = lambda x: inflection.underscore( x )\n",
    "        cols_new = list( map( snakecase, cols_old) )\n",
    "\n",
    "        # rename columns\n",
    "        df1.columns = cols_new\n",
    "\n",
    "        # ------ 1.3. Data Types ----------------------------------------------\n",
    "        df1['date'] = pd.to_datetime( df1['date'] )\n",
    "\n",
    "        # ------- 1.5. Fillout NA ---------------------------------------------\n",
    "        # competition_distance\n",
    "        df1['competition_distance'] = df1['competition_distance'].apply( lambda x: 200000.0 if math.isnan( x ) else x )\n",
    "\n",
    "        # competition_open_since_month\n",
    "        df1['competition_open_since_month'] = df1.apply( lambda x: x['date'].month if math.isnan( x['competition_open_since_month'] ) else x['competition_open_since_month'], axis=1 )\n",
    "\n",
    "        # competition_open_since_year\n",
    "        df1['competition_open_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['competition_open_since_year'] ) else x['competition_open_since_year'], axis=1 )\n",
    "\n",
    "        # promo2_since_week\n",
    "        df1['promo2_since_week'] = df1.apply( lambda x: x['date'].week if math.isnan( x['promo2_since_week'] ) else x['promo2_since_week'], axis=1 )\n",
    "\n",
    "        # promo2_since_year\n",
    "        df1['promo2_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['promo2_since_year'] ) else x['promo2_since_year'], axis=1 )\n",
    "\n",
    "        # promo_interval\n",
    "        month_map = {1: 'Jan', 2: 'Fev', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dez' }\n",
    "\n",
    "        df1['promo_interval'].fillna( 0, inplace=True )\n",
    "        df1['month_map'] = df1['date'].dt.month.map( month_map)\n",
    "        df1['is_promo'] = df1[['promo_interval', 'month_map']].apply( lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split( ',' ) else 0, axis=1 )\n",
    "\n",
    "        # ------ 1.6. Change Types -------------------------------------------\n",
    "        # competition\n",
    "        df1['competition_open_since_month'] = df1['competition_open_since_month'].astype('int64')\n",
    "        df1['competition_open_since_year'] = df1['competition_open_since_year'].astype('int64')\n",
    "\n",
    "        # promo2\n",
    "        df1['promo2_since_week'] = df1['promo2_since_week'].astype('int64')\n",
    "        df1['promo2_since_year'] = df1['promo2_since_year'].astype('int64')\n",
    "\n",
    "        return df1\n",
    "    \n",
    "    def feature_engineering( self, df2 ):\n",
    "\n",
    "        # year\n",
    "        df2['year'] = df2['date'].dt.year\n",
    "\n",
    "        # month\n",
    "        df2['month'] = df2['date'].dt.month\n",
    "\n",
    "        # day\n",
    "        df2['day'] = df2['date'].dt.day\n",
    "\n",
    "        # week of year\n",
    "        df2['week_of_year'] = df2['date'].dt.weekofyear\n",
    "\n",
    "        # year week\n",
    "        df2['year_week'] = df2['date'].dt.strftime('%Y-%W')\n",
    "\n",
    "        # competition since\n",
    "        df2['competition_since'] = df2.apply( lambda x: datetime.datetime( year=x['competition_open_since_year'], month=x['competition_open_since_month'], day=1 ), axis=1 )\n",
    "        df2['competition_time_month'] = (( df2['date'] - df2['competition_since'])/30).apply(lambda x: x.days).astype(int)\n",
    "\n",
    "        # promo since\n",
    "        df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' + df2['promo2_since_week'].astype( str )\n",
    "        df2['promo_since'] = df2['promo_since'].apply(lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w') - datetime.timedelta(days=7) )\n",
    "        df2['promo_time_week'] = (( df2['date'] -  df2['promo_since'])/7).apply(lambda x: x.days).astype( int )\n",
    "\n",
    "        # assortment\n",
    "        df2['assortment'] = df2['assortment'].apply(lambda x: 'basic' if x =='a' else 'extra' if x =='b' else 'extended' )\n",
    "\n",
    "        # state holiday\n",
    "        df2['state_holiday'] = df2['state_holiday'].apply(lambda x: 'public_holiday' if x =='a' else 'easter_holiday' if x =='b' else 'christmas' if x =='c' else 'regulary_day' )\n",
    "\n",
    "        # ------ 3.0 STEP 3 - VARIABLES FILTERING -----------------------\n",
    "        # 3.1. lines Filtering\n",
    "        df2 = df2[df2['open'] !=0]\n",
    "        \n",
    "        # 3.2. Columns Selections\n",
    "        cols_drop =['open', 'promo_interval', 'month_map']\n",
    "        df2 = df2.drop(cols_drop, axis=1)\n",
    "        \n",
    "        return df2\n",
    "    \n",
    "    def data_preparation( self, df5 ):\n",
    "        # ------- 5.2. Rescaling -------------------------------------\n",
    "        # competition distance\n",
    "        df5['competition_distance'] = self.competition_distance_scaler.fit_transform( df5[['competition_distance']].values )\n",
    "        \n",
    "        # competition_time_month\n",
    "        df5['competition_time_month'] = self.competition_time_month_scaler.fit_transform( df5[['competition_time_month']].values )\n",
    "        \n",
    "        # promo_time_week\n",
    "        df5['promo_time_week'] = self.promo_time_week_scaler.fit_transform( df5[['promo_time_week']].values )\n",
    "        \n",
    "        # year\n",
    "        df5['year'] = self.year_scaler.fit_transform( df5[['year']].values )\n",
    "        \n",
    "        # ------ 5.5.1. Encoding -------------------------------------\n",
    "        # State_holiday - one Hot Encoding\n",
    "        df5 = pd.get_dummies( df5, prefix=['state_holiday'], columns=['state_holiday'] )\n",
    "\n",
    "        # Store_type - Label encoding\n",
    "        df5['store_type'] = self.store_type_scaler.fit_transform( df5['store_type'] )\n",
    "\n",
    "        # assortment - Ordinal Encoding\n",
    "        assortment_dict={'basic': 1, 'extra': 2, 'extended':3}\n",
    "        df5['assortment'] = df5['assortment'].map(assortment_dict)\n",
    "        \n",
    "        # ------ 5.3.2 Nature Transformation -------------------------        \n",
    "        # day_of_week\n",
    "        df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x * ( 2. * np.pi/7)))\n",
    "        df5['day_of_week_cos'] = df5['day_of_week'].apply( lambda x: np.cos( x * ( 2. * np.pi/7)))\n",
    "\n",
    "        # month\n",
    "        df5['month_sin'] = df5['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12)))\n",
    "        df5['month_cos'] = df5['month'].apply( lambda x: np.cos( x * ( 2. * np.pi/12)))\n",
    "\n",
    "        # day\n",
    "        df5['day_sin'] = df5['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/30)))\n",
    "        df5['day_cos'] = df5['day'].apply( lambda x: np.cos( x * ( 2. * np.pi/30)))\n",
    "\n",
    "        # week_of_year\n",
    "        df5['week_of_year_sin'] = df5['week_of_year'].apply( lambda x: np.sin( x * ( 2. * np.pi/52)))\n",
    "        df5['week_of_year_cos'] = df5['week_of_year'].apply( lambda x: np.cos( x * ( 2. * np.pi/52)))\n",
    "\n",
    "        # Boruta columns selected\n",
    "        cols_selected = [ 'store', 'promo', 'store_type', 'assortment', 'competition_distance', 'competition_open_since_month',\n",
    "                          'competition_open_since_year', 'promo2', 'promo2_since_week', 'promo2_since_year', 'competition_time_month',\n",
    "                          'promo_time_week', 'day_of_week_sin', 'day_of_week_cos', 'month_sin', 'month_cos', 'day_sin', 'day_cos',\n",
    "                          'week_of_year_sin', 'week_of_year_cos']       \n",
    "        \n",
    "        return df5[ cols_selected ]\n",
    "            \n",
    "    def get_prediction( self, model, original_data, test_data ):\n",
    "       \n",
    "        # prediction\n",
    "        pred = model.predict( test_data )\n",
    "        \n",
    "        # join pred into the original data\n",
    "        original_data['prediction'] = np.expm1( pred )\n",
    "        \n",
    "        return original_data.to_json( orient='records', date_format='iso')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486220d",
   "metadata": {},
   "source": [
    "## <font Color=\"Blue\">10.2 API Hander</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b947fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Import Libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from flask             import Flask, request, Response\n",
    "from rossmann.Rossmann import Rossmann\n",
    "\n",
    "# loading model\n",
    "model = pickle.load( open('C:/Users/frmoriya/Documents/repos/ds_producao_hosmann/model_result/model_rossmann.pkl', 'rb') )\n",
    "\n",
    "# initialize API\n",
    "app = Flask( __name__ )\n",
    "\n",
    "@app.route( '/rossmann/predict', methods=['POST'] )\n",
    "\n",
    "def rossmann_predict():\n",
    "    test_json = request.get_json()\n",
    "    \n",
    "    # Test json Return\n",
    "    if test_json: # there is data \n",
    "        \n",
    "        if isinstance( test_json, dict ): # unique example\n",
    "            test_raw = pd.DataFrame( test_json, index[0] )\n",
    "            \n",
    "        else: #multiple example\n",
    "            test_raw = pd.DataFrame( test_json, columns=test_json[0].keys() )\n",
    "            \n",
    "        # instantiate Rossmann Class\n",
    "        pipeline = Rossmann( )\n",
    "        \n",
    "        # data cleaning\n",
    "        df1 = pipeline.data_cleaning( test_raw )\n",
    "        \n",
    "        # feature engineering\n",
    "        df2 = pipeline.feature_engineering( df1 )\n",
    "        \n",
    "        # data preparation\n",
    "        df3 = pipeline.data_preparation( df2 )\n",
    "        \n",
    "        # prediction\n",
    "        df_response = pipeline.get_prediction( model, test_raw, df3 )\n",
    "        \n",
    "        return df_response\n",
    "    \n",
    "    else:\n",
    "        return Response( '{}', status=200, mimetype='application/json')\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #app.run( '0.0.0.0', debug=True )\n",
    "    app.run( '0.0.0.0' )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a27a4",
   "metadata": {},
   "source": [
    "## <font Color=\"Blue\">10.3 Api Tester</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fecd43f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T02:20:26.670764Z",
     "start_time": "2022-05-12T02:20:24.013839Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a96252f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T02:21:04.682151Z",
     "start_time": "2022-05-12T02:21:04.654155Z"
    }
   },
   "outputs": [],
   "source": [
    "#Data Store (contem as caracteristicas das lojas)\n",
    "df_store_raw = pd.read_csv( 'data/store.csv', low_memory=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64255903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T02:26:51.190375Z",
     "start_time": "2022-05-12T02:26:51.120362Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "\n",
    "df10 = pd.read_csv('C:/Users/frmoriya/Documents/repos/ds_producao_hosmann/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f37d340",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T02:29:07.076295Z",
     "start_time": "2022-05-12T02:29:07.037283Z"
    }
   },
   "outputs": [],
   "source": [
    "# merge test dataset + store\n",
    "df_test = pd.merge( df10, df_store_raw, how='left', on='Store')\n",
    "\n",
    "# choose store for predictions\n",
    "#df_test = df_test[df_test['Store'] == 200]\n",
    "df_test = df_test[df_test['Store'].isin( [20,10,100,] )]\n",
    "\n",
    "# remove closed days\n",
    "df_test = df_test[df_test['Open'] !=0]\n",
    "df_test = df_test[~df_test['Open'].isnull()]\n",
    "df_test = df_test.drop( 'Id', axis=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00a76ca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T02:29:10.655147Z",
     "start_time": "2022-05-12T02:29:10.630158Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert Dataframe to json\n",
    "data =  json.dumps( df_test.to_dict( orient='records' ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1e23723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T02:29:14.643360Z",
     "start_time": "2022-05-12T02:29:13.170391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code 200\n"
     ]
    }
   ],
   "source": [
    "# API CALL\n",
    "\n",
    "#url = 'https://rossmann-predict-model.herokuapp.com/rossmann/predict'\n",
    "url = 'https://rossman-web.herokuapp.com//rossmann/predict'\n",
    "header = {'content-type':'application/json'}\n",
    "data = data\n",
    "\n",
    "r = requests.post( url, data=data, headers=header )\n",
    "print( 'Status Code {}'.format( r.status_code) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b667de37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T02:29:19.568519Z",
     "start_time": "2022-05-12T02:29:19.541521Z"
    }
   },
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame( r.json(), columns=r.json()[0].keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb94e813",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T02:29:22.093989Z",
     "start_time": "2022-05-12T02:29:22.063990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store Number:10, will sell R$ 213,932.25 in the next 6 weeks.\n",
      "Store Number:20, will sell R$ 301,375.82 in the next 6 weeks.\n",
      "Store Number:100, will sell R$ 298,694.26 in the next 6 weeks.\n"
     ]
    }
   ],
   "source": [
    "d2 = d1[['store', 'prediction']].groupby( 'store' ).sum().reset_index()\n",
    "\n",
    "for i in range ( len(d2)):\n",
    "    print( 'Store Number:{}, will sell R$ {:,.2f} in the next 6 weeks.'.format(\n",
    "            d2.loc[i, 'store'],\n",
    "            d2.loc[i, 'prediction'] ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b9ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e879f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
